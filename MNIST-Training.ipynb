{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2olKBLRhCbaB"
   },
   "source": [
    "# Training on MNIST dataset for Handwritten Number Recogniton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWjtH1_lCjhV"
   },
   "source": [
    "### Importing Libraries and important stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jPW-7hKwCWyr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5Wl5DUJCqKo"
   },
   "source": [
    "### Loading Data and preprocessing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mR_DOprNCun3"
   },
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype('float64') / 255\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype('float64') / 255\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSrKIoeVDTnS"
   },
   "source": [
    "### Building our Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fvBD_OJDYeT",
    "outputId": "5dc61a39-0b8b-403e-d2bb-766f02fb0033"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Building the model architechture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIKE_FPeDi0h"
   },
   "source": [
    "### Training our CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "KF5AVEu5Dndm",
    "outputId": "a228271c-3728-4a5e-95ab-81476068b188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9057 - loss: 0.2995 - val_accuracy: 0.9799 - val_loss: 0.0637\n",
      "Epoch 2/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0452 - val_accuracy: 0.9882 - val_loss: 0.0406\n",
      "Epoch 3/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0258 - val_accuracy: 0.9891 - val_loss: 0.0395\n",
      "Epoch 4/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9945 - loss: 0.0163 - val_accuracy: 0.9877 - val_loss: 0.0410\n",
      "Epoch 5/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9957 - loss: 0.0125 - val_accuracy: 0.9881 - val_loss: 0.0465\n",
      "Epoch 6/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0099 - val_accuracy: 0.9861 - val_loss: 0.0543\n",
      "Epoch 7/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0087 - val_accuracy: 0.9873 - val_loss: 0.0627\n",
      "Epoch 8/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0060 - val_accuracy: 0.9892 - val_loss: 0.0487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bb3266e570>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=8, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2f2HbbnVDx-5"
   },
   "source": [
    "### Evaluating the Accuracy of our CNN on a given test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NlmhxUbkD6SL",
    "outputId": "c48c1fd5-4514-478a-d130-94e267d9c408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 2ms/step - accuracy: 0.9881 - loss: 0.0460\n",
      "Test accuracy: 0.988099992275238\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1x1umbc1D9Nc"
   },
   "source": [
    "### Saving the model to a .h5 file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-U8dxHU4EFz8",
    "outputId": "e8dc433c-47b5-45ae-8dc5-4134c908a434"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"mnist_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SHOfSV3Fy86"
   },
   "source": [
    "Now we use the tkinter program to draw a number and we input that number to our trained and saved NN (remember the .h5 file?)\n",
    "\n",
    "\n",
    "Go use that program to draw a number and upload it here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzbNLp-WHO8h"
   },
   "source": [
    "### Inverting the handwritten number image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bxrl3maTG75A"
   },
   "source": [
    "The following code snippet will invert the black and white image making it similar to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "E4jqNlDaGoOo"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "image = Image.open('drawn_image.png')\n",
    "inverted_image = PIL.ImageOps.invert(image)\n",
    "inverted_image.save('drawn_inv_image.png')\n",
    "\n",
    "image = Image.open('drawn_inv_image.png')\n",
    "inverted_image = PIL.ImageOps.invert(image)\n",
    "plt.imshow(inverted_image, cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11Fda-jQH-_K"
   },
   "source": [
    "### Use the drawing program and upload it\n",
    "\n",
    "Here's the code for it, run it in your local environment\n",
    "\n",
    "```\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Create a Tkinter window\n",
    "class DrawingApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Drawing Canvas\")\n",
    "        \n",
    "        # Canvas for drawing\n",
    "        self.canvas = tk.Canvas(root, width=280, height=280, bg='white')\n",
    "        self.canvas.pack()\n",
    "        \n",
    "        # Initialize drawing state\n",
    "        self.drawing = False\n",
    "        self.last_x, self.last_y = None, None\n",
    "        \n",
    "        # Event bindings\n",
    "        self.canvas.bind(\"<ButtonPress-1>\", self.start_drawing)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw)\n",
    "        self.canvas.bind(\"<ButtonRelease-1>\", self.stop_drawing)\n",
    "        \n",
    "        # Button to save the drawing\n",
    "        save_button = tk.Button(root, text=\"Save\", command=self.save_image)\n",
    "        save_button.pack()\n",
    "        \n",
    "        # Image to save drawing\n",
    "        self.image = Image.new(\"L\", (280, 280), \"white\")\n",
    "        self.draw_instance = ImageDraw.Draw(self.image)\n",
    "    \n",
    "    def start_drawing(self, event):\n",
    "        self.drawing = True\n",
    "        self.last_x, self.last_y = event.x, event.y\n",
    "    \n",
    "    def draw(self, event):\n",
    "        if self.drawing:\n",
    "            # Draw on canvas\n",
    "            self.canvas.create_line(self.last_x, self.last_y, event.x, event.y, fill=\"black\", width=10)\n",
    "            \n",
    "            # Draw on PIL image\n",
    "            self.draw_instance.line([self.last_x, self.last_y, event.x, event.y], fill=\"black\", width=10)\n",
    "            \n",
    "            self.last_x, self.last_y = event.x, event.y\n",
    "    \n",
    "    def stop_drawing(self, event):\n",
    "        self.drawing = False\n",
    "    \n",
    "    def save_image(self):\n",
    "        self.image = self.image.resize((28, 28))  # Resize to MNIST dimensions\n",
    "        self.image.save(\"drawn_image.png\")\n",
    "        print(\"Image saved as drawn_image.png\")\n",
    "\n",
    "\n",
    "# Run the application\n",
    "root = tk.Tk()\n",
    "app = DrawingApp(root)\n",
    "root.mainloop()\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rc9JM6wlIBT8",
    "outputId": "ec4a451a-e1f3-4fe0-8b73-deed8dced435"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "Predicted digit: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7744</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">495,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7744\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m495,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">515,148</span> (1.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m515,148\u001b[0m (1.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">515,146</span> (1.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m515,146\u001b[0m (1.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image  # Import the Image class from Pillow\n",
    "import numpy as np\n",
    "\n",
    "# Load the drawn image\n",
    "img = Image.open(\"drawn_inv_image.png\")\n",
    "\n",
    "# Preprocess the image\n",
    "img_array = np.array(img)  # Normalize pixel values to [0, 1]\n",
    "img_array = img_array.reshape(1, 28, 28, 1)  # Add batch and channel dimensions\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"mnist_cnn_model.h5\")\n",
    "\n",
    "# Predict the digit\n",
    "prediction = model.predict(tf.convert_to_tensor(img_array, dtype=tf.float64))\n",
    "print(prediction)\n",
    "predicted_digit = np.argmax(prediction)  # Get the digit with the highest probability\n",
    "print(\"Predicted digit:\", predicted_digit)\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
