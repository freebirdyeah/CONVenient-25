{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Character Recognition with PyTorch\n",
    "\n",
    "## Import Libraries\n",
    "### The code uses PyTorch's utils.data and torchvision for dataset handling and transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T14:22:17.637869Z",
     "iopub.status.busy": "2025-01-23T14:22:17.637463Z",
     "iopub.status.idle": "2025-01-23T14:22:48.168130Z",
     "shell.execute_reply": "2025-01-23T14:22:48.167203Z",
     "shell.execute_reply.started": "2025-01-23T14:22:17.637829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, ConcatDataset, random_split\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applies Transformations: \n",
    "   ### First we convert the images to grayscale (since we train on EMNIST AND it has only grayscale images)\n",
    "   ### Normalizes the pixel values (to help the model train more effectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads the EMNIST Dataset:\n",
    "   ### Downloads the EMNIST dataset, which includes images of letters.\n",
    "   ### Combines the train and test parts to form the usable dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.EMNIST(root='./data', split='letters', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.EMNIST(root='./data', split='letters', train=False, download=True, transform=transform)\n",
    "\n",
    "# Making the full datatset by joining the train_dataset and test_dataset\n",
    "full_dataset = ConcatDataset([train_dataset, test_dataset])\n",
    "total_len = len(full_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracts a Subset\n",
    "### Takes 30% of the combined dataset for quick training (don't want to spend all day here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset size (30% of total): 43680\n"
     ]
    }
   ],
   "source": [
    "# defining percent of portion to use and not to use\n",
    "portion_size = int(0.3 * total_len)   \n",
    "unused_size = total_len - portion_size\n",
    "\n",
    "# actually getting the 30% from the dataset\n",
    "subset_30_percent, _ = random_split(\n",
    "    full_dataset,\n",
    "    [portion_size, unused_size],\n",
    "    generator=torch.Generator().manual_seed(42)   # this here makes sure we always get the same examples in the 30% we choose\n",
    ")\n",
    "\n",
    "print(f\"Subset size (30% of total): {len(subset_30_percent)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splits the Subset: \n",
    "### Divides the 30% subset into:\n",
    "   - ### 90% for training.\n",
    "   - ### 10% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New training size (90% of 30% subset): 39312\n",
      "New testing size (10% of 30% subset): 4368\n"
     ]
    }
   ],
   "source": [
    "# Within that 30%, split 90% for training and 10% for testing\n",
    "train_size = int(0.9 * len(subset_30_percent))  \n",
    "test_size = len(subset_30_percent) - train_size\n",
    "new_train_subset, new_test_subset = random_split(\n",
    "    subset_30_percent,\n",
    "    [train_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# prints out the number of examples we have in the train/test sets\n",
    "print(f\"New training size (90% of 30% subset): {len(new_train_subset)}\")\n",
    "print(f\"New testing size (10% of 30% subset): {len(new_test_subset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates DataLoaders\n",
    "\n",
    "### Converts the training and testing subsets into DataLoaders for easier batch processing during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders from these new subsets --> Basically loading stuff up for our use\n",
    "train_loader = DataLoader(new_train_subset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(new_test_subset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once again, setting up some important external stuff\n",
    "### We are using the torch.nn library to define our Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:19:51.508712Z",
     "iopub.status.busy": "2025-01-23T13:19:51.508334Z",
     "iopub.status.idle": "2025-01-23T13:20:04.170416Z",
     "shell.execute_reply": "2025-01-23T13:20:04.169098Z",
     "shell.execute_reply.started": "2025-01-23T13:19:51.508687Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't Worry About the fancy stuff!\n",
    "\n",
    "### `class` --> Our Blueprint, under here we define our Neural Network\n",
    "### `__init__` --> Sets up stuff (A Constructor for those of you who paid attention in OOPs class)\n",
    "### `super()` --> Gives access to properties of the parent (nn.Module)\n",
    "### `forward()` --> Defines how input is processed, one instance of front prop \n",
    "\n",
    "### Convolution -> https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "\n",
    "### Max Pool -> https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool2d.html\n",
    "\n",
    "### ReLU (Rectified Linear Unit) -> https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html\n",
    "\n",
    "### Fully Connected (FC Linear Layer) -> https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "\n",
    "### Flatten has been done for you through view(), do it before you start putting FC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1)  # Output: (16, 28, 28)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(8*14*14, 64)\n",
    "        self.fc2 = nn.Linear(64, 27)  # 27 classes for EMNIST (letters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with ReLU and MaxPooling\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))  # Output: (16, 14, 14)\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)  # Shape: (batch_size, 64*3*3)\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's count the number of trainable parameters we have\n",
    "\n",
    "#### we define our `model` to be the `SimpleCNN()` object we wrote down\n",
    "#### the `p.numel() for p in model.parameters() if p.requires_grad` only picks those params which undergo training  \n",
    "#### i.e. it only picks trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:07:27.562388Z",
     "iopub.status.busy": "2025-01-23T13:07:27.561962Z",
     "iopub.status.idle": "2025-01-23T13:07:28.293420Z",
     "shell.execute_reply": "2025-01-23T13:07:28.291199Z",
     "shell.execute_reply.started": "2025-01-23T13:07:27.562355Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 102251\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN()\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total Parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we define the loss function we are going to use!\n",
    "### We will use the CrossEntropyLoss function\n",
    "### We also use an optimizer function called Adam to make our Gradient Descent quicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:07:28.877608Z",
     "iopub.status.busy": "2025-01-23T13:07:28.877248Z",
     "iopub.status.idle": "2025-01-23T13:07:28.883568Z",
     "shell.execute_reply": "2025-01-23T13:07:28.882294Z",
     "shell.execute_reply.started": "2025-01-23T13:07:28.877579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Device\n",
    "\n",
    "### `torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")` checks if a GPU (CUDA) is available and sets the computation device accordingly. If no GPU is available, it defaults to the CPU.\n",
    "    \n",
    "### `model.to(device)` moves the model to the selected device (GPU or CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:07:29.639491Z",
     "iopub.status.busy": "2025-01-23T13:07:29.638956Z",
     "iopub.status.idle": "2025-01-23T13:11:48.007944Z",
     "shell.execute_reply": "2025-01-23T13:11:48.006479Z",
     "shell.execute_reply.started": "2025-01-23T13:07:29.639436Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1568, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=27, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training loop\n",
    "\n",
    "### we define the number of epochs, running_loss keeps track of the loss per epoch\n",
    "### the inner loop, passes the images and their labels (what's written on it... the answers) to the model in device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.1540\n",
      "Epoch [2/5], Loss: 0.5775\n",
      "Epoch [3/5], Loss: 0.4597\n",
      "Epoch [4/5], Loss: 0.4019\n",
      "Epoch [5/5], Loss: 0.3609\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Resets the derivative turn in gradient descent after every backprop\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass, criteria for determining the loss is the output answer and the answers we have (label)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add whatever loss was calculated per image-label to the running loss\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see how accurate it is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:11:48.009941Z",
     "iopub.status.busy": "2025-01-23T13:11:48.009537Z",
     "iopub.status.idle": "2025-01-23T13:11:49.910691Z",
     "shell.execute_reply": "2025-01-23T13:11:49.909268Z",
     "shell.execute_reply.started": "2025-01-23T13:11:48.009889Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 87.25%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's save our trained Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:11:49.912992Z",
     "iopub.status.busy": "2025-01-23T13:11:49.912554Z",
     "iopub.status.idle": "2025-01-23T13:11:49.922145Z",
     "shell.execute_reply": "2025-01-23T13:11:49.921197Z",
     "shell.execute_reply.started": "2025-01-23T13:11:49.912951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"pytorch_ocr.pth\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
